# MiddleClaw

A lightweight system troubleshooting agent powered by [Ollama](https://ollama.com). MiddleClaw diagnoses system issues interactively â€” reading config files, running diagnostic commands, executing scripts, and applying fixes â€” but **only with your explicit approval**.

![Node](https://img.shields.io/badge/Node.js-18%2B-green) ![Platform](https://img.shields.io/badge/Platform-Linux%20%7C%20macOS%20%7C%20Windows-blue) ![License](https://img.shields.io/badge/License-ISC-lightgrey)

---

## Quick Start

### Option A: One-Command Install

Don't have Node.js? The installer handles everything â€” detecting your OS, installing Node if needed, pulling dependencies, and starting the server.

**macOS / Linux:**
```bash
chmod +x install.sh
./install.sh
```

**Windows:**
```
Double-click install.bat
```

The installer will:
1. Check for Node.js v18+ and offer to install it if missing
2. Run `npm install` to pull dependencies
3. Create a default `middleclaw.config.json` with OS-appropriate settings
4. Check for Ollama and warn if it's not installed
5. Start the server

### Option B: Manual Setup

If you already have Node.js 18+ and Ollama:

```bash
# Pull a model (if you haven't already)
ollama pull glm-4.7:cloud

# Install dependencies
npm install

# Start MiddleClaw
npm start
```

Then open **http://localhost:3334** in your browser.

### First-Run Setup

The first time you start MiddleClaw (with no `middleclaw.config.json` present), it runs an interactive setup in your terminal, asking you to configure the model, Ollama URL, OpenClaw directory, OS, and paths. It also auto-detects available Ollama models so you can pick from a list.

You can control this behavior with flags:

| Flag | Effect |
|---|---|
| `-i` / `--interactive` | Always run the setup prompts, even if a config already exists |
| `-y` / `--yes` | Skip all prompts and use defaults (or existing config) |

```bash
# Re-run setup to change settings
node server.mjs -i

# Skip setup entirely (CI, scripts, etc.)
node server.mjs -y

# Or via npm
npm run setup      # same as -i
npm run start:quick  # same as -y
```

---

## Features

- **Interactive diagnostics** â€” describe an issue in plain English, and MiddleClaw walks through it step by step
- **Approval-gated actions** â€” every file read, command, script execution, and file write requires your explicit approval before it runs
- **Script execution** â€” run `.sh`, `.bash`, `.bat`, `.cmd`, and `.ps1` scripts directly from readable directories
- **Automatic backups** â€” any file modified by MiddleClaw is backed up first to `.middleclaw-backups/`
- **Session tabs** â€” run multiple troubleshooting sessions side by side, with full history persisted in your browser
- **Settings UI** â€” configure everything from the gear icon in the header, no config file editing required
- **Dark mode** â€” toggle between light and dark themes
- **OS-aware** â€” commands and shell syntax adapt to your configured operating system
- **Experimental: Audio Conversing** â€” talk to MiddleClaw using your microphone (speech-to-text) and hear responses spoken aloud (text-to-speech) via [ElevenLabs](https://elevenlabs.io). See [EXPERIMENTAL-FEATS.md](EXPERIMENTAL-FEATS.md) for setup and details.

---

## Configuration

All settings can be managed from the **Settings panel** (gear icon âš™ in the top-right corner of the UI). Changes to paths take effect immediately; changes to port, model, or Ollama URL require a restart.

Settings are stored in `middleclaw.config.json`:

```json
{
  "port": 3333,
  "ollama_url": "http://localhost:11434",
  "model": "glm-4.7:cloud",
  "openclaw_dir": "/opt/openclaw",
  "os": "linux",
  "read_paths": [
    "/etc/",
    "/var/log/",
    "/tmp/",
    "/home/",
    "/opt/"
  ],
  "write_paths": [
    "/tmp/",
    "/opt/openclaw"
  ]
}
```

| Setting | Description | Default |
|---|---|---|
| `port` | Server port | `3333` |
| `ollama_url` | Ollama API endpoint | `http://localhost:11434` |
| `model` | Ollama model to use | `glm-4.7:cloud` |
| `openclaw_dir` | OpenClaw installation directory | `/opt/openclaw` |
| `os` | Operating system (`linux`, `macos`, `windows`) | `linux` |
| `read_paths` | Directories MiddleClaw can read from | See above |
| `write_paths` | Directories MiddleClaw can write to | See above |

Environment variables `PORT`, `OLLAMA_URL`, and `MIDDLECLAW_MODEL` override config file values.

---

## How It Works

MiddleClaw uses a local LLM through Ollama to diagnose system issues. When it needs to interact with your system, it requests one of four action types:

| Action | What It Does | Access Rule |
|---|---|---|
| **Read File** | Reads a file's contents | Must be in a readable path |
| **Run Command** | Executes a shell command | Checked against a blocklist of dangerous patterns |
| **Run Script** | Executes a `.sh`, `.bat`, `.cmd`, or `.ps1` script | Script must be in a readable path |
| **Write File** | Creates or modifies a file | Must be in a writable path; original is backed up first |

Each action appears as a card in the chat with **Approve** and **Deny** buttons. Nothing runs until you approve it. If an action is denied or fails, MiddleClaw explains what happened and suggests an alternative.

---

## Safety

MiddleClaw enforces multiple layers of protection:

**Approval required** â€” every action goes through an approve/deny flow before execution. There are no automatic or silent operations.

**Path restrictions** â€” file reads and writes are limited to the directories you configure. Attempts to access anything outside those paths are blocked.

**Command blocklist** â€” dangerous command patterns are rejected before they reach the approval step, including `rm -rf`, `mkfs`, `dd`, `shutdown`, `reboot`, fork bombs, piping untrusted scripts to shell, and more.

**Automatic backups** â€” before any file is modified, the original is copied to `.middleclaw-backups/` with a timestamp. You can always roll back.

**Script sandboxing** â€” scripts run with the script's directory as the working directory and have a 60-second timeout.

**Command timeout** â€” individual commands are limited to 30 seconds to prevent hangs.

---

## Project Structure

```
middleclaw/
â”œâ”€â”€ server.mjs                 # Express server, Ollama proxy, action executor
â”œâ”€â”€ public/
â”‚   â””â”€â”€ index.html             # Single-file frontend (chat UI, settings, tabs)
â”œâ”€â”€ middleclaw.config.json     # User configuration (created on first run)
â”œâ”€â”€ package.json               # Node.js project config
â”œâ”€â”€ install.sh                 # macOS/Linux installer
â”œâ”€â”€ install.bat                # Windows installer
â”œâ”€â”€ .middleclaw-backups/       # Auto-created backup directory
â”œâ”€â”€ README.md
â””â”€â”€ EXPERIMENTAL-FEATS.md      # Documentation for experimental features
```

---

## Troubleshooting

**"Cannot reach Ollama"** â€” Make sure Ollama is running (`ollama serve`) and the URL in settings matches. Default is `http://localhost:11434`.

**"Model not found"** â€” Pull the model first: `ollama pull glm-4.7:cloud`. Or change the model in Settings to one you've already pulled.

**Port already in use** â€” Change the port in Settings or start with `PORT=4000 npm start`.

**Path access denied** â€” Open Settings (gear icon) and add the directory to the readable or writable paths list.

---

## ðŸš¨ Calling All Hands â€” Contributors Wanted!

> **Want to help build the future of system diagnostics?**
>
> MiddleClaw is growing and we need developers like YOU to help shape what comes next. Whether you're into AI, frontend, backend, DevOps, or just love tinkering with system tools â€” there's a place for you here.
>
> **ðŸ“¬ Reach out to join the project:**
>
> ### **[dev@doctorclaw.ai](mailto:dev@doctorclaw.ai)**
>
> Drop us a line, tell us what you're passionate about, and let's build something great together. All skill levels welcome.

---

## About MiddleClaw

MiddleClaw is a clone/fork of [DoctorClaw](https://doctorclaw.ai), designed to work in parallel with the original for testing and development purposes.

**Original DoctorClaw:** https://doctorclaw.ai  
**Email for the original project:** dev@doctorclaw.ai

MiddleClaw retains all the same functionality as DoctorClaw while running on a separate port (3334) with its own configuration.

---

## Requirements

- **Node.js** 18+ (the installer can set this up for you)
- **Ollama** running locally with a pulled model
- A modern browser (Chrome, Firefox, Safari, Edge)
